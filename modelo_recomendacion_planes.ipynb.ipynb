{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto de Machine Learning: Clasificación de Planes de Megaline\n",
    "\n",
    "## Introducción\n",
    "\n",
    "La compañía móvil **Megaline** se enfrenta a un desafío importante: muchos de sus clientes siguen utilizando planes antiguos, mientras que la empresa ha lanzado dos nuevos planes más competitivos llamados **Smart** y **Ultra**. Nuestro objetivo en este proyecto es ayudar a Megaline a desarrollar un modelo que pueda analizar el comportamiento de sus clientes y recomendar el plan adecuado entre estos dos nuevos planes. \n",
    "\n",
    "Contamos con datos que incluyen el comportamiento mensual de los usuarios que ya han migrado a uno de estos dos planes. Usaremos este dataset para entrenar un modelo que, basándose en las características de uso, pueda predecir si un cliente debería estar en el plan **Smart** o en el plan **Ultra**.\n",
    "\n",
    "## Descripción de los datos\n",
    "\n",
    "El dataset **`users_behavior.csv`** contiene la siguiente información sobre el comportamiento mensual de los usuarios:\n",
    "\n",
    "- **calls**: Número de llamadas realizadas por el usuario en el mes.\n",
    "- **minutes**: Duración total de las llamadas en minutos.\n",
    "- **messages**: Número de mensajes de texto enviados por el usuario.\n",
    "- **mb_used**: Tráfico de Internet utilizado en megabytes (MB).\n",
    "- **is_ultra**: Etiqueta del plan en el mes actual (Ultra - 1, Smart - 0).\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Nuestro objetivo es desarrollar un modelo de clasificación que pueda predecir con la mayor precisión posible si un cliente debería estar en el plan **Smart** o en el plan **Ultra**. El umbral de precisión requerido es de al menos **0.75**. \n",
    "\n",
    "Trabajaremos con diferentes modelos y ajustaremos los hiperparámetros para optimizar el rendimiento del modelo, usando conjuntos de datos divididos en entrenamiento, validación y prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Abrir y examinar el archivo de datos\n",
    "\n",
    "En este primer paso, comenzaremos por abrir el conjunto de datos proporcionado **`users_behavior.csv`**, que contiene información sobre el comportamiento mensual de los usuarios de Megaline. La primera tarea será cargar los datos y examinarlos para entender la estructura del dataset y verificar que los datos sean apropiados para el análisis. Esto incluye observar el tamaño del conjunto de datos, las columnas disponibles y una primera mirada a las estadísticas básicas de las variables.\n",
    "\n",
    "El objetivo es familiarizarnos con los datos y asegurarnos de que estén listos para ser procesados en los siguientes pasos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo de datos\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "# Ver las primeras filas del dataset\n",
    "df.head()\n",
    "\n",
    "# Mostrar información general sobre el dataset\n",
    "df.info()\n",
    "\n",
    "# Ver estadísticas básicas de las variables numéricas\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de la inspección inicial de los datos\n",
    "\n",
    "El dataset **`users_behavior.csv`** contiene un total de **3,214 observaciones** y **5 columnas** que describen el comportamiento de los usuarios de Megaline. Cada fila representa un registro mensual del comportamiento de un usuario, con las siguientes características:\n",
    "\n",
    "- **calls**: Número de llamadas realizadas en el mes.\n",
    "- **minutes**: Duración total de las llamadas en minutos.\n",
    "- **messages**: Número de mensajes de texto enviados en el mes.\n",
    "- **mb_used**: Tráfico de Internet utilizado en megabytes (MB).\n",
    "- **is_ultra**: Etiqueta binaria que indica si el usuario utiliza el plan **Ultra** (1) o el plan **Smart** (0).\n",
    "\n",
    "### Detalles importantes:\n",
    "- El dataset **no tiene valores nulos**, lo que significa que no necesitaremos lidiar con datos faltantes, lo cual facilita el análisis.\n",
    "- Las columnas **calls**, **minutes**, **messages**, y **mb_used** son de tipo `float64`, mientras que la columna **is_ultra** es de tipo `int64`, ya que representa una variable categórica binaria.\n",
    "- Observamos que los valores de las variables **calls**, **minutes**, **messages**, y **mb_used** tienen diferentes rangos de variabilidad:\n",
    "  - **calls**: Va de 0 a 244 llamadas por mes.\n",
    "  - **minutes**: Va de 0 a 1632 minutos por mes.\n",
    "  - **messages**: Va de 0 a 224 mensajes por mes.\n",
    "  - **mb_used**: Va de 0 MB a 49,745 MB por mes.\n",
    "\n",
    "### Conclusión referente a los datos:\n",
    "Los datos están limpios y listos para ser segmentados en conjuntos de entrenamiento, validación y prueba. En el próximo paso, procederemos a esta segmentación para entrenar y evaluar nuestros modelos de clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Segmentación del dataset en conjuntos de entrenamiento, validación y prueba\n",
    "\n",
    "En este paso, segmentaremos los datos en tres conjuntos: **entrenamiento**, **validación** y **prueba**. Esta división es fundamental para evaluar la calidad de los modelos de manera efectiva.\n",
    "\n",
    "- **Conjunto de entrenamiento**: Se utilizará para entrenar los modelos. Este conjunto contendrá la mayor parte de los datos.\n",
    "- **Conjunto de validación**: Se utilizará para ajustar los hiperparámetros de los modelos y seleccionar el modelo con el mejor rendimiento.\n",
    "- **Conjunto de prueba**: Una vez elegido el mejor modelo y ajustados los hiperparámetros, usaremos este conjunto para realizar la evaluación final del rendimiento del modelo. Esto nos permitirá determinar si el modelo generaliza bien a datos que no ha visto antes.\n",
    "\n",
    "Vamos a dividir el dataset de la siguiente manera:\n",
    "- **60%** de los datos para el conjunto de **entrenamiento**.\n",
    "- **20%** de los datos para el conjunto de **validación**.\n",
    "- **20%** de los datos para el conjunto de **prueba**.\n",
    "\n",
    "Para realizar esta división, utilizaremos la función `train_test_split` de la librería **scikit-learn**, que nos permite realizar una división aleatoria de los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 1928\n",
      "Tamaño del conjunto de validación: 643\n",
      "Tamaño del conjunto de prueba: 643\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir las características (features) y el objetivo (target)\n",
    "features = df.drop(['is_ultra'], axis=1)  # Todas las columnas excepto 'is_ultra'\n",
    "target = df['is_ultra']  # La columna objetivo es 'is_ultra'\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (60%) y un conjunto temporal (40%) para validación y prueba\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345)\n",
    "\n",
    "# Dividir el conjunto temporal en conjunto de validación (20%) y conjunto de prueba (20%)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Imprimir el tamaño de cada conjunto para verificar la segmentación\n",
    "print(f'Tamaño del conjunto de entrenamiento: {len(features_train)}')\n",
    "print(f'Tamaño del conjunto de validación: {len(features_valid)}')\n",
    "print(f'Tamaño del conjunto de prueba: {len(features_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Investigación de la calidad de diferentes modelos\n",
    "\n",
    "En este paso, probaremos diferentes modelos de clasificación para identificar cuál ofrece el mejor rendimiento en términos de exactitud. Probaremos una variedad de algoritmos, ajustando sus hiperparámetros para mejorar la calidad de las predicciones.\n",
    "\n",
    "El objetivo es encontrar el modelo que proporcione una precisión igual o superior a **0.75** en el conjunto de validación, que es el umbral que se requiere para este proyecto.\n",
    "\n",
    "Los modelos que investigaremos incluyen:\n",
    "1. **Árbol de Decisión (Decision Tree)**\n",
    "2. **Bosque Aleatorio (Random Forest)**\n",
    "3. **Regresión Logística (Logistic Regression)**\n",
    "\n",
    "Para cada uno de estos modelos, ajustaremos los hiperparámetros relevantes y calcularemos la exactitud en el conjunto de validación. Luego, seleccionaremos el mejor modelo basándonos en su rendimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del Árbol de Decisión: 0.7138\n",
      "Exactitud del Bosque Aleatorio: 0.7854\n",
      "\n",
      "Resultados de exactitud en el conjunto de validación:\n",
      "Árbol de Decisión: 0.7138\n",
      "Bosque Aleatorio: 0.7854\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir un diccionario para almacenar los resultados de exactitud de los diferentes modelos\n",
    "results = {}\n",
    "\n",
    "# Modelo 1: ÁRBOL DE DECISIÓN\n",
    "# Entrenamos un modelo de Árbol de Decisión\n",
    "tree_model = DecisionTreeClassifier(random_state=12345)\n",
    "tree_model.fit(features_train, target_train)\n",
    "tree_predictions = tree_model.predict(features_valid)\n",
    "\n",
    "# Calcular la exactitud del Árbol de Decisión\n",
    "tree_accuracy = accuracy_score(target_valid, tree_predictions)\n",
    "results['Árbol de Decisión'] = tree_accuracy\n",
    "print(f\"Exactitud del Árbol de Decisión: {tree_accuracy:.4f}\")\n",
    "\n",
    "# Modelo 2: BOSQUE ALEATORIO\n",
    "# Entrenamos un modelo de Bosque Aleatorio\n",
    "forest_model = RandomForestClassifier(random_state=12345, n_estimators=100)\n",
    "forest_model.fit(features_train, target_train)\n",
    "forest_predictions = forest_model.predict(features_valid)\n",
    "\n",
    "# Calcular la exactitud del Bosque Aleatorio\n",
    "forest_accuracy = accuracy_score(target_valid, forest_predictions)\n",
    "results['Bosque Aleatorio'] = forest_accuracy\n",
    "print(f\"Exactitud del Bosque Aleatorio: {forest_accuracy:.4f}\")\n",
    "\n",
    "# Imprimir los resultados finales para comparar los modelos\n",
    "print(\"\\nResultados de exactitud en el conjunto de validación:\")\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud de la Regresión Logística: 0.7589\n",
      "\n",
      "Resultados de exactitud en el conjunto de validación:\n",
      "Árbol de Decisión: 0.7138\n",
      "Bosque Aleatorio: 0.7854\n",
      "Regresión Logística: 0.7589\n"
     ]
    }
   ],
   "source": [
    "# Modelo 3: REGRESIÓN LOGÍSTICA\n",
    "# Entrenamos un modelo de Regresión Logística\n",
    "log_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "log_model.fit(features_train, target_train)\n",
    "log_predictions = log_model.predict(features_valid)\n",
    "\n",
    "# Calcular la exactitud de la Regresión Logística\n",
    "log_accuracy = accuracy_score(target_valid, log_predictions)\n",
    "results['Regresión Logística'] = log_accuracy\n",
    "print(f\"Exactitud de la Regresión Logística: {log_accuracy:.4f}\")\n",
    "\n",
    "# Imprimir los resultados finales actualizados para comparar los tres modelos\n",
    "print(\"\\nResultados de exactitud en el conjunto de validación:\")\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de la evaluación inicial de los modelos\n",
    "\n",
    "Hasta este punto, hemos evaluado tres modelos diferentes de clasificación para recomendar un plan a los usuarios de Megaline: **Árbol de Decisión**, **Bosque Aleatorio**, y **Regresión Logística**. A continuación, se presentan los resultados de exactitud en el conjunto de validación para cada modelo:\n",
    "\n",
    "- **Árbol de Decisión**: 0.7138\n",
    "- **Bosque Aleatorio**: 0.7854\n",
    "- **Regresión Logística**: 0.7589\n",
    "\n",
    "### Análisis de los resultados:\n",
    "- El **Árbol de Decisión** presentó el menor rendimiento, con una exactitud del 71.38%. Si bien el modelo ofrece una interpretación clara, no logra superar el umbral mínimo de exactitud de **0.75**.\n",
    "- La **Regresión Logística** alcanzó una exactitud de **0.7589**, superando el umbral requerido. Este modelo es adecuado para clasificaciones binarias simples, como en este caso.\n",
    "- Sin embargo, el **Bosque Aleatorio** ha sido el modelo más exitoso hasta ahora, con una exactitud de **0.7854**, lo que lo convierte en el mejor modelo de los tres evaluados.\n",
    "\n",
    "### Próximo paso: Ajuste de hiperparámetros del Bosque Aleatorio\n",
    "Para mejorar aún más el rendimiento del **Bosque Aleatorio**, ajustaremos dos de sus hiperparámetros más importantes:\n",
    "1. **n_estimators**: El número de árboles en el bosque.\n",
    "2. **max_depth**: La profundidad máxima de los árboles.\n",
    "\n",
    "Realizaremos una búsqueda exhaustiva probando diferentes valores para estos hiperparámetros y seleccionaremos la mejor combinación basándonos en la exactitud obtenida en el conjunto de validación. El objetivo es superar el rendimiento actual de **0.7854** de exactitud.\n",
    "\n",
    "Una vez completado este ajuste, seleccionaremos el modelo final para la evaluación en el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor exactitud: 0.7947 con n_estimators = 100 y max_depth = 5\n"
     ]
    }
   ],
   "source": [
    "# Ajuste de hiperparámetros del Bosque Aleatorio\n",
    "best_accuracy = 0\n",
    "best_estimators = 0\n",
    "best_depth = 0\n",
    "\n",
    "for n_estimators in range(50, 151, 50):  # Probar con diferentes números de árboles\n",
    "    for max_depth in range(5, 16, 5):  # Probar con diferentes profundidades máximas\n",
    "        forest_model = RandomForestClassifier(random_state=12345, n_estimators=n_estimators, max_depth=max_depth)\n",
    "        forest_model.fit(features_train, target_train)\n",
    "        forest_predictions = forest_model.predict(features_valid)\n",
    "        accuracy = accuracy_score(target_valid, forest_predictions)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_estimators = n_estimators\n",
    "            best_depth = max_depth\n",
    "\n",
    "# Imprimir el mejor modelo encontrado\n",
    "print(f\"Mejor exactitud: {best_accuracy:.4f} con n_estimators = {best_estimators} y max_depth = {best_depth}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Evaluación final del modelo en el conjunto de prueba\n",
    "\n",
    "Después de ajustar los hiperparámetros del **Bosque Aleatorio** y seleccionar el mejor modelo, procederemos a evaluar su rendimiento final en el **conjunto de prueba**. Este conjunto contiene datos que el modelo no ha visto ni durante el entrenamiento ni durante la validación, lo que nos permitirá obtener una evaluación justa de cómo se comportará el modelo en situaciones del mundo real.\n",
    "\n",
    "El objetivo es obtener una exactitud de al menos **0.75** en el conjunto de prueba. Dado que el modelo ha alcanzado una exactitud de **0.7947** en el conjunto de validación, esperamos que su rendimiento en el conjunto de prueba sea similar o mejor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo en el conjunto de prueba: 0.7900\n"
     ]
    }
   ],
   "source": [
    "# Evaluación final del modelo en el conjunto de prueba\n",
    "\n",
    "# Usamos el mejor modelo encontrado con n_estimators=100 y max_depth=5\n",
    "final_model = RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=5)\n",
    "final_model.fit(features_train, target_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "test_predictions = final_model.predict(features_test)\n",
    "\n",
    "# Calcular la exactitud en el conjunto de prueba\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "\n",
    "# Imprimir el resultado de la evaluación final\n",
    "print(f\"Exactitud del modelo en el conjunto de prueba: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación final del modelo en el conjunto de prueba\n",
    "\n",
    "Después de haber ajustado los hiperparámetros y seleccionado el mejor modelo, evaluamos el **Bosque Aleatorio** con los parámetros óptimos en el **conjunto de prueba**. Este conjunto contiene datos que el modelo no ha visto antes, por lo que nos brinda una evaluación precisa de su rendimiento en situaciones del mundo real.\n",
    "\n",
    "### Resultados de la evaluación final:\n",
    "- **Exactitud del modelo en el conjunto de prueba**: 0.7900\n",
    "\n",
    "### Análisis:\n",
    "El modelo ha alcanzado una exactitud del **79.00%** en el conjunto de prueba, lo cual supera el umbral mínimo de **0.75** establecido para el proyecto. Esto indica que el modelo es confiable y puede hacer predicciones precisas sobre el plan que mejor se adapta a los usuarios de Megaline.\n",
    "\n",
    "### Conclusión:\n",
    "En resumen, después de evaluar varios modelos de clasificación, incluyendo el **Árbol de Decisión**, **Bosque Aleatorio**, y **Regresión Logística**, el **Bosque Aleatorio** demostró ser el modelo con mejor rendimiento. Al ajustar sus hiperparámetros, logramos mejorar su exactitud tanto en el conjunto de validación como en el conjunto de prueba.\n",
    "\n",
    "Con una exactitud del **79.00%** en el conjunto de prueba, el modelo cumple con los requisitos del proyecto y puede ser utilizado para predecir con éxito el plan adecuado (Smart o Ultra) para los usuarios de Megaline basándose en su comportamiento de llamadas, mensajes y uso de datos.\n",
    "\n",
    "Este modelo puede ser implementado por Megaline para optimizar sus recomendaciones de planes y mejorar la satisfacción del cliente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de cordura del modelo\n",
    "\n",
    "Para verificar que nuestro modelo de **Bosque Aleatorio** esté funcionando correctamente y no presente errores fundamentales, realizamos una prueba de cordura. En esta prueba, comparamos el rendimiento del modelo con un método de predicción simple: devolver siempre el valor promedio del plan más común.\n",
    "\n",
    "El objetivo de esta prueba es asegurarnos de que nuestro modelo predice mejor que un método trivial y que el desempeño no se debe simplemente al azar o a predicciones constantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud de la predicción constante (prueba de cordura): 0.6843\n"
     ]
    }
   ],
   "source": [
    "# Prueba de cordura: predicción constante basada en el valor más común (mayoría)\n",
    "\n",
    "# El plan más común en el conjunto de entrenamiento\n",
    "most_common = target_train.mode()[0]\n",
    "\n",
    "# Hacemos predicciones constantes basadas en el valor más común para todos los usuarios del conjunto de prueba\n",
    "constant_predictions = [most_common] * len(target_test)\n",
    "\n",
    "# Calculamos la exactitud de esta predicción constante\n",
    "constant_accuracy = accuracy_score(target_test, constant_predictions)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Exactitud de la predicción constante (prueba de cordura): {constant_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de cordura del modelo\n",
    "\n",
    "Para asegurarnos de que el modelo de **Bosque Aleatorio** no esté haciendo predicciones triviales, realizamos una prueba de cordura. En esta prueba, comparamos el rendimiento del modelo con una predicción constante basada en el plan más común del conjunto de entrenamiento. El objetivo era verificar que el modelo predice mejor que una suposición simple.\n",
    "\n",
    "### Resultados de la prueba de cordura:\n",
    "- **Exactitud de la predicción constante**: 0.6843\n",
    "- **Exactitud del Bosque Aleatorio**: 0.7900\n",
    "\n",
    "### Análisis:\n",
    "El modelo de **Bosque Aleatorio** supera significativamente la predicción constante, con un **10.57%** de mejora en la exactitud. Esto confirma que el modelo no está haciendo predicciones triviales y está utilizando los datos de comportamiento del cliente para predecir de manera más precisa si un cliente debería tener el plan **Smart** o **Ultra**.\n",
    "\n",
    "El modelo ha pasado la prueba de cordura con éxito y puede ser implementado para predecir con confianza los planes de los usuarios de **Megaline**.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 844,
    "start_time": "2024-10-15T23:20:29.385Z"
   },
   {
    "duration": 36,
    "start_time": "2024-10-15T23:21:45.092Z"
   },
   {
    "duration": 443,
    "start_time": "2024-10-15T23:33:25.462Z"
   },
   {
    "duration": 437,
    "start_time": "2024-10-15T23:42:11.644Z"
   },
   {
    "duration": 12,
    "start_time": "2024-10-15T23:44:57.706Z"
   },
   {
    "duration": 2360,
    "start_time": "2024-10-15T23:51:31.270Z"
   },
   {
    "duration": 203,
    "start_time": "2024-10-15T23:54:00.790Z"
   },
   {
    "duration": 6,
    "start_time": "2024-10-16T00:00:35.803Z"
   },
   {
    "duration": 5,
    "start_time": "2024-10-16T00:02:11.843Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
